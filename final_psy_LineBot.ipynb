{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickLin1225/Final-Psy-LineBot/blob/main/final_psy_LineBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZCXr2K0xKFH",
        "outputId": "16d7fca5-60c1-40f3-c45e-ded6a86f816f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghRhh3d8xVF0"
      },
      "outputs": [],
      "source": [
        "!pip install line-bot-sdk flask\n",
        "!pip install pyngrok\n",
        "!ngrok authtoken 2QrnEFtjjMkbdQs609UXhiHh7JP_41yYQ94u84CsaxFZoiaJ5\n",
        "!git clone https://github.com/THUDM/ChatGLM2-6B"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 添加peft、opencc\n",
        "!pip install -r /content/ChatGLM2-6B/requirements.txt"
      ],
      "metadata": {
        "id": "ncmG3B_9DtT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip chatGLM2_6B_QLoRA_t16_v5-20230729T023644Z-001.zip"
      ],
      "metadata": {
        "id": "8uxSxLS2D1ll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel, BitsAndBytesConfig\n",
        "from peft import PeftModel, PeftConfig\n",
        "import torch\n",
        "base_model_path = \"THUDM/chatglm2-6b\"\n",
        "peft_model_path = \"/content/chatGLM2_6B_QLoRA_t16_v5/checkpoint-1700\"\n",
        "\n",
        "config = PeftConfig.from_pretrained(peft_model_path)\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_path, trust_remote_code=True)\n",
        "base_model = AutoModel.from_pretrained(base_model_path,\n",
        "                      trust_remote_code=True,\n",
        "                      device='cuda')\n",
        "\n",
        "model = PeftModel.from_pretrained(base_model, peft_model_path)"
      ],
      "metadata": {
        "id": "VSMu16LmD6DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0vBOOJICnlv"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, abort\n",
        "from linebot.models.events import FollowEvent\n",
        "from linebot import LineBotApi, WebhookHandler\n",
        "from linebot.exceptions import InvalidSignatureError\n",
        "from linebot.models import *\n",
        "import requests\n",
        "from pyngrok import ngrok\n",
        "import json\n",
        "import opencc\n",
        "import csv\n",
        "\n",
        "# 建置主程序\n",
        "app = Flask(__name__)\n",
        "# Channel access token\n",
        "line_bot_api = LineBotApi(\"lDOvYWU5DjtPpSVFrNKfNAejGKKSZvKYvhVMBR1ND1zmh8Got+JtoF4EgpWRconwzhxkKWWpwbIsby4+vLETeg+dMhUU8M6mL+7dmNFnHl1QbtdT66wv3gIlj90GKuECO7r/q/wVPkkNnCGtnsfRKAdB04t89/1O/w1cDnyilFU=\")\n",
        "# Channel secret\n",
        "handler = WebhookHandler(\"f8f7fe98ab2ebbf5c4af4ace91a7b7f1\")\n",
        "\n",
        "\n",
        "# 啟動server對外接口，使line能夠丟消息進來\n",
        "@app.route(\"/\", methods=['POST'])\n",
        "def callback():\n",
        "    signature = request.headers['X-Line-Signature']\n",
        "    body = request.get_data(as_text=True)\n",
        "    try:\n",
        "        handler.handle(body, signature)\n",
        "    except InvalidSignatureError:\n",
        "        abort(400)\n",
        "\n",
        "    return 'OK'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "回應用戶，歡迎用的文字消息\n",
        "\n",
        "'''\n",
        "\n",
        "@handler.add(FollowEvent)\n",
        "def reply_text_and_get_user_profile(event):\n",
        "    line_bot_api.reply_message(\n",
        "        event.reply_token,\n",
        "        [TextSendMessage('哈囉，歡迎來到心理聊天室，有什麼問題都可以跟我說呦！')]\n",
        "    )"
      ],
      "metadata": {
        "id": "WUYGLz9Vuo5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@handler.add(MessageEvent, message=TextMessage)\n",
        "def handle_line_text(event):\n",
        "    response = chat_with_llm(event.source.user_id, event.message.text)\n",
        "    line_bot_api.reply_message(event.reply_token, messages=[TextSendMessage(response)])\n",
        "\n",
        "def chat_with_llm(user_id, input_text):\n",
        "    user_profile = line_bot_api.get_profile(user_id)\n",
        "    prmpts = \"现在你是一名专业的心理咨商师，根据下列发问者所提供之问题一步步进行思考，并以第一人称口吻给出答复。\\n问题描述：\"\n",
        "\n",
        "    cc = opencc.OpenCC('tw2s')\n",
        "    converted_input = cc.convert(input_text)\n",
        "\n",
        "    cc = opencc.OpenCC('s2tw')\n",
        "    response, history = model.chat(tokenizer, prmpts + converted_input, history=[], repetition_penalty=1.2)\n",
        "    response = '\\n'.join(response.replace(\". \", \".\").split()).replace(\",\", \"，\").replace(\".\", \". \")\n",
        "    converted_response = cc.convert(response)\n",
        "    field_names = [\"user_id\", \"display_name\", \"picture_url\", \"status_message\", \"input_text\", \"response\"]\n",
        "\n",
        "    # 將用戶資料以及聊天紀錄存至users.csv\n",
        "    with open(\"/content/drive/MyDrive/users.csv\", \"a\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=field_names)\n",
        "\n",
        "        if csvfile.tell() == 0:\n",
        "            writer.writeheader()\n",
        "\n",
        "        writer.writerow({\n",
        "            \"user_id\": user_profile.user_id,\n",
        "            \"display_name\": user_profile.display_name,\n",
        "            \"picture_url\": user_profile.picture_url,\n",
        "            \"status_message\": user_profile.status_message,\n",
        "            \"input_text\": input_text,\n",
        "            \"response\": converted_response\n",
        "        })\n",
        "    return converted_response"
      ],
      "metadata": {
        "id": "6Je_4wuNHQNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIzt2NElyQZL"
      },
      "outputs": [],
      "source": [
        "# 主程序運行\n",
        "port = 5000\n",
        "# Open a ngrok tunnel to the HTTP server\n",
        "public_url = ngrok.connect(port).public_url\n",
        "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))\n",
        "app.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSdB4bIQeaMdAjHWylbByp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}